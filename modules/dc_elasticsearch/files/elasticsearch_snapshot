#!/usr/bin/python
"""
A simple script to perform an elastic search backup
And more importantly CLEAN UP AFTER ITSELF
"""

# pylint: disable=import-error

import argparse
import datetime
import logging
import time

import elasticsearch.client as elasticsearch

LOG = logging.getLogger(__name__)

MILLISECONDS_IN_A_DAY = 86400000
SECONDS_IN_A_DAY = 86400


def backup(client, repo):
    """Create a snapshot tagged with todays date"""

    date = datetime.date.today()
    name = '{:02}_{:02}_{}'.format(date.month, date.day, date.year)
    client.snapshot.create(repo, name, master_timeout=SECONDS_IN_A_DAY, wait_for_completion=True)


def keep_snapshot(snapshot, threshold):
    """Whether to keep a snapshot or not"""

    return snapshot['start_time_in_millis'] > threshold


def cleanup(client, repo, keep):
    """Clean up snapshots older than the keep time"""

    # Work out the cut off point
    threshold = int(time.time() * 1000) - (keep * MILLISECONDS_IN_A_DAY)

    # Grab a list of all existing snapshots
    snapshots = client.snapshot.get(repo, '_all')['snapshots']
    LOG.info('Found %d snapshots', len(snapshots))

    retain = [snapshot for snapshot in snapshots if keep_snapshot(snapshot, threshold)]
    for snapshot in retain:
        LOG.info('Keeping snapshot %s state %s', snapshot['snapshot'], snapshot['state'])

    delete = [snapshot for snapshot in snapshots if not keep_snapshot(snapshot, threshold)]
    for snapshot in delete:
        # Get the name and decode into a date...
        name = snapshot['snapshot']

        # nuke it from orbit
        LOG.info('Deleting snapshot %s state %s', name, snapshot['state'])
        client.snapshot.delete(repo, name, master_timeout=SECONDS_IN_A_DAY)


def main():
    """Perform a cron o'clock backup"""

    parser = argparse.ArgumentParser()
    parser.add_argument('-H', '--host', type=str, default='localhost')
    parser.add_argument('-p', '--port', type=int, default=9200)
    parser.add_argument('-r', '--repo', required=True)
    parser.add_argument('-k', '--keep', type=int, default=30)
    args = parser.parse_args()

    formater = logging.Formatter(
        fmt='%(asctime)s.%(msecs)03d %(process)d %(levelname)s %(name)s %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S')

    handler = logging.StreamHandler()
    handler.setFormatter(formater)

    logging.getLogger().addHandler(handler)
    logging.getLogger().setLevel(logging.INFO)

    client = elasticsearch.Elasticsearch([args.host + ':' + str(args.port)])

    backup(client, args.repo)
    cleanup(client, args.repo, args.keep)


if __name__ == '__main__':
    main()

# vi: ts=4 et:
