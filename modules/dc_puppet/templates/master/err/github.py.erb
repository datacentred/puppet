from errbot import BotPlugin, botcmd
from HTMLParser import HTMLParser
import logging
import re
import subprocess
import random
import urllib2
import json
import threading
import Queue
import base64

# A queue to store requests
queue = Queue.Queue()
branches = []
coalesce_size = 0

class MLStripper(HTMLParser):
    """
    Strips all the HTML tags out of a string
    """

    def __init__(self):
        """
        Initialization
        """
        self.reset()
        self.fed = []

    def handle_data(self, data):
        """
        Data, bits on in tags get appended to the list
        """
        self.fed.append(data)

    def handle_entityref(self, ref):
        """
        Hopefully you don't have &amp; and stuff in your username
        or branch titles!!
        """
        logging.warning('[GitBot] warning unhandled entity reference ' + ref)

    def get_data(self):
        """
        Concatenate all the data to get a single string
        """
        return ''.join(self.fed)

##############################################################################
# My Little Pony: Friendship Is Magic
##############################################################################

def get_pony():
    """Return a random pony"""
    path = 'http://ponies.<%= @domain %>/'
    resp = urllib2.urlopen(path + 'ponies.json')
    ponies = json.loads(resp.read())
    return path + random.choice(ponies)

##############################################################################
# Git
##############################################################################

def git_sync():
    """Synchronise repos and submodules"""
    # Become the git user and fetch the production branch, this
    # is a bare repository so we need to fast forward the destination
    # reference to that of the source
    # todo: The actual branch name is available in the regex
    #       matches above, probably buggers up with submodules
    subprocess.call(['sudo', '-H', '-u', 'git', 'bash', '-c',
                     'cd /home/git/puppet.git; ' \
                     'git fetch origin master:master'])

    # Likewise mirror changes to the puppet environment
    # todo: The actual branch name is available in the regex
    #       matches above, probably buggers up with submodules
    subprocess.call(['sudo', '-H', '-u', 'git', 'bash', '-c',
                     'cd /etc/puppet/environments/production;' \
                     'git pull;' \
                     'git submodule init;' \
                     'git submodule sync;' \
                     'git submodule update'])

def git_delete(branch):
    """Delete a branch and kill off the dynamic environment"""
    subprocess.call(['sudo', '-H', '-u', 'git', 'bash', '-c',
                     'cd /home/git/puppet.git; ' \
                     'git branch -D {0}'.format(branch)])
    subprocess.call(['sudo', '-H', '-u', 'git', 'bash', '-c',
                     'cd /home/git/puppet.git; ' \
                     'git push origin :{0}'.format(branch)])
    subprocess.call(['sudo', '-H', '-u', 'git', 'bash', '-c',
                     'rm -rf /etc/puppet/environments/{0}'.format(branch)])

##############################################################################
# Foreman
##############################################################################

HOST     = '<%= @foreman_url %>'
DOMAIN   = '<%= @domain %>'
USERNAME = 'admin'
PASSWORD = '<%= @foreman_admin_pw %>'

def foreman_get(path):
    """GET from the foreman"""
    url = 'https://{0}.{1}{2}'.format(HOST, DOMAIN, path)
    request = urllib2.Request(url)
    # Add in the plain-text authorization header
    auth = base64.encodestring("{0}:{1}".format(USERNAME, PASSWORD))
    request.add_header('Authorization', 'Basic {0}'.format(auth))
    # May raise urllib2.URLError
    response = urllib2.urlopen(request)
    if response.getcode() != 200:
        logging.info('[Worker] GET exception: ' + url)
        raise Exception
    return response.read()

def foreman_post(path, post):
    """POST to the foreman"""
    url = 'https://{0}.{1}{2}'.format(HOST, DOMAIN, path)
    request = urllib2.Request(url)
    # Add in the plain-text authorization header
    auth = base64.encodestring("{0}:{1}".format(USERNAME, PASSWORD))
    request.add_header('Authorization', 'Basic {0}'.format(auth))
    # May raise urllib2.URLError
    response = urllib2.urlopen(request, post)
    if response.getcode() != 200:
        logging.info('[Worker] POST exception: ' + url)
        raise Exception
    return response.read()

def get_smart_proxy_id(name):
    """Given the textual name lookup a smart proxy"""
    resp = foreman_get('/api/smart_proxies')
    data = json.loads(resp)
    for proxy in data:
        if proxy['smart_proxy']['name'] == name:
            return proxy['smart_proxy']['id']
    logging.info('[Worker] smart proxy exception: ' + url)
    raise Exception

def get_environment_id(name):
    """Given the textual name lookup an environment"""
    resp = foreman_get('/api/environments')
    data = json.loads(resp)
    for environment in data:
        if environment['environment']['name'] == name:
            return environment['environment']['id']
    logging.info('[Worker] environment exception: ' + url)
    raise Exception

def post_update_puppetclasses(proxy, env):
    """Update all puppet classes for the specified environment"""
    path = '/api/smart_proxies/{0}/import_puppetclasses'.format(proxy)
    data = 'environment_id={0}'.format(env)
    foreman_post(path, data)

def foreman_sync():
    """Import all puppet classes from the master's production env"""
    proxy = get_smart_proxy_id('Puppet Master')
    env = get_environment_id('production')
    post_update_puppetclasses(proxy, env)

##############################################################################
# Utilities
##############################################################################

lock = threading.Lock()

def enqueue_job(branch):
    """Add a branch merge to the job queue(s)"""
    lock.acquire()
    branches.append(branch)
    lock.release()
    queue.put(0)

def wait_job():
    """Wait for a job to become available"""
    global coalesce_size
    queue.get()
    # Dequeue as many jobs as possible and merge
    # into a single synchronisation
    lock.acquire()
    coalesce_size = 1
    while True:
        try:
            queue.get(False)
        except Queue.Empty:
            break
        coalesce_size += 1
    lock.release()

def dequeue_job():
    """Remove the job(s) from the job queue(s)"""
    global coalesce_size
    lock.acquire()
    # Pop and ack all the jobs we coalesced
    for temp in range(coalesce_size):
        branches.pop(0)
        queue.task_done()
    coalesce_size = 0
    lock.release()

def kill_environment():
    """Kill off a dynamic environment"""
    lock.acquire()
    for environment in branches[:coalesce_size]:
        ary = environment.split('/')
        if len(ary) == 2:
            git_delete(ary[1])
    lock.release()

def dump_queue():
    """Print out the current job queue status"""
    # Multi line input must be given via /quote
    # or the newlines will be ignored
    output = "/quote "
    lock.acquire()
    if len(branches) == 0:
        output += "Job queue empty"
    else:
        output += "Current job(s):\n"
        for i in branches[:coalesce_size]:
            output += "  {0}\n".format(i)
        if len(branches) > coalesce_size:
            output += "Queued job(s):\n"
            for i in branches[coalesce_size:]:
                output += "  {0}\n".format(i)
    lock.release()
    return output

##############################################################################
# Updater thread
##############################################################################

def worker_main(*args, **kwargs):
    """
    As we can have multiple pull requests happen at once
    we process them asynchronously in this thread to ensure
    that both foreman and the puppet repos are totally in sync
    with GitHub
    """
    logging.info('[Worker] started child')
    while True:
        logging.info('[Worker] wait queue')
        wait_job()
        logging.info('[Worker] syncing git')
        git_sync()
        logging.info('[Worker] deleting dynamic environment')
        kill_environment()
        logging.info('[Worker] syncing foreman')
        foreman_sync()
        logging.info('[Worker] sync complete')
        dequeue_job()

##############################################################################
# Actual errbot plugin!
##############################################################################

class GitHub(BotPlugin):
    """
    GitHub plugin for Marvin Bot running locally on the puppet master
    """
    def __init__(self):
        """Constructor"""
        worker = threading.Thread(target=worker_main)
        worker.daemon = True
        worker.start()
        BotPlugin.__init__(self)
    
    def __del__(self):
        """Destructor"""
        queue.join()

    def callback_message(self, conn, message):
        """
        Process incoming messages and take any action that is required
        """
        # Never hurts to log what we were attempting
        logging.debug('[GitBot] ' + message.getFrom().getNode())
        logging.debug('[GitBot] ' + message.getBody())
        logging.debug('[GitBot] ' + message.getType())

        # Remove all the markup from the body to allow easier parsing
        stripper = MLStripper()
        stripper.feed(message.getBody())
         
        # Okay so we could be a bit fuzzier, this will break first :)
        match = re.match(r'(.+?) pushed to branch (\S+) of (\S+)' \
                         r' - Merge pull request #(\d+) from (\S+)',
                         stripper.get_data())

        if match != None:
            # Provide visual feed back in the channel that we're
            # actually doing something.  Ponies are good for this
            self.send(message.getFrom(), match.group(1) +
                      ' performed a pull request merge',
                      message_type=message.getType())
            self.send(message.getFrom(), get_pony(),
                      message_type=message.getType())
            enqueue_job(match.group(5))

    @botcmd
    def pony(self, msg, args):
        """Print a pony! And test the daemon obviously"""
        return get_pony()

    @botcmd
    def sync(self, msg, args):
        """Print a pony and sync the repos explicitly"""
        enqueue_job('no-branch')
        return get_pony()

    @botcmd
    def queue(self, msg, args):
        """Interrogate the run queue"""
        return dump_queue()
    
# vim: set syntax=python ts=4 et:
