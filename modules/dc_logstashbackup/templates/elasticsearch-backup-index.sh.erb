#!/bin/bash
# 
# elasticsearch-backup-index.sh
#
# Push logstash index from yesterday to a backup directory with an accompanying restore script.
#   http://logstash.net
#   http://www.elasticsearch.org
#
# Modified for DC from https://github.com/imperialwicket/elasticsearch-logstash-index-mgmt
#
#   Inspiration: 
#     http://tech.superhappykittymeow.com/?p=296
# 
# Must run on an elasticsearch node, and expects to find the index on this node.

usage()
{
cat << EOF

elasticsearch-backup-index.sh

Create a restorable backup of an elasticsearch index (assumes Logstash format
indexes), and copy it to a backup directory. The default backs up an
index from yesterday. Note that this script itself does not restart 
elasticsearch - the restore script that is generated for each backup will 
restart elasticsearch after restoring an archived index.

USAGE: ./elasticsearch-backup-index.sh -b BACKUP_DIR -i INDEX_DIRECTORY [OPTIONS]

OPTIONS:
  -h    Show this message
  -b    Path for backups (Required)
  -i    Elasticsearch index directory (Required)
  -d    Backup a specific date (format: YYYY.mm.dd)
  -s    Shards (default: 5)
  -r    Replicas (default: 0)
  -e    Elasticsearch URL (default: http://localhost:9200)
  -n    How nice tar must be (default: 19)
  -u    Restart command for elastic search (default 'service elasticsearch restart')

EXAMPLES:

  ./elasticsearch-backup-index.sh -b "/var/backups" \
  -i "/usr/local/elasticsearch/data/node/0/indices"
 
    This uses http://localhost:9200 to connect to elasticsearch and backs up
    the index from yesterday (based on system time, be careful with timezones)

  ./elasticsearch-backup-index.sh -b "/tmp" -i "/mnt/es/data/node/0/indices" \
  -d "2013.05.21" -t "/mnt/es/backups" \
  -u "service es restart" -e "http://127.0.0.1:9200" -p

    Connect to elasticsearch using 127.0.0.1 instead of localhost, backup the
    index from 2013.05.21 instead of yesterday, store the archive and restore script in /tmp
    and use 'service es restart' to restart elastic search.

EOF
}

if [ "$USER" != 'root' ] && [ "$LOGNAME" != 'root' ]; then
  # I don't want to troubleshoot the permissions of others
  echo "This script must be run as root."
  exit 1
fi

# Defaults
BACKUPDIR=/var/backup
SHARDS=5
REPLICAS=0
ELASTICSEARCH="http://localhost:9200"
NICE=19
RESTART="service elasticsearch restart"

# Validate shard/replica values
RE_D="^[0-9]+$"

if [ $# == 0 ] 
then
	usage
	exit 1
fi

while getopts ":b:i:d:c:s:r:e:n:u:h" flag
do
  case "$flag" in
    h)
      usage
      exit 0
      ;;
    b)
      BACKUP_DIR=$OPTARG
      ;;
    i)
      INDEX_DIR=$OPTARG
      ;;
    d)
      DATE=$OPTARG
      ;;
    s)
      if [[ $OPTARG =~ $RE_D ]]; then
        SHARDS=$OPTARG
      else
        ERROR="${ERROR}Shards must be an integer.\n"
      fi
      ;;
    r)
      if [[ $OPTARG =~ $RE_D ]]; then
        REPLICAS=$OPTARG
      else
        ERROR="${ERROR}Replicas must be an integer.\n"
      fi
      ;;
    e)
      ELASTICSEARCH=$OPTARG
      ;;
    n)
      if [[ $OPTARG =~ $RE_D ]]; then
        NICE=$OPTARG
      fi
      # If nice is not an integer, just use default
      ;;
    u)
      RESTART=$OPTARG
      ;;
    *)
      usage
      exit 1
      ;;
  esac
done

# We need a backup dir
if [ -z "BACKUP_DIR" ]; then
  ERROR="${ERROR}Please provide a backup directory path with -b.\n"
fi

# We need an elasticsearch index directory
if [ -z "INDEX_DIR" ]; then
  ERROR="${ERROR}Please provide an Elasticsearch index directory with -i.\n"
fi

# If we have errors, show the errors with usage data and exit.
if [ -n "$ERROR" ]; then
  echo -e $ERROR
  usage
  exit 1
fi

# Make sure we have curl
if ! which curl >/dev/null
then echo "This script requires curl - please install it"
exit 1
fi

# Try and mount the backup directory
if ! mount <%= @nfs_backup_server %>:<%= @storagedir %>/backups/<%= @hostname %>-logstashbackup <%= @logstashbackupmount %>
then echo "Could not mount remote backup directory"
exit 1
fi

# Default logstash index naming is hardcoded, as are YYYY-mm container directories.
if [ -n "$DATE" ]; then
  INDEX="logstash-$DATE"
  YEARMONTH=${DATE//\./-}
  YEARMONTH=${YEARMONTH:0:7}
else
  INDEX=`date --date='yesterday' +"logstash-%Y.%m.%d"`
  YEARMONTH=`date --date='yesterday' +"%Y-%m"`
fi
BACKUPDIR_TARGET="$BACKUP_DIR/$YEARMONTH"

# Make sure there is an index
if ! [ -d $INDEX_DIR/$INDEX ]; then
  echo "The index $INDEX_DIR/$INDEX does not appear to exist."
  exit 1
fi

# Get metadata from elasticsearch
INDEX_MAPPING=`curl -s -XGET "$ELASTICSEARCH/$INDEX/_mapping"`
SETTINGS="{\"settings\":{\"number_of_shards\":$SHARDS,\"number_of_replicas\":$REPLICAS},\"mappings\":$INDEX_MAPPING}"

# Make the tmp directory if it does not already exist.
if ! [ -d $BACKUPDIR_TARGET ]; then
  mkdir -p $BACKUPDIR_TARGET
fi

# Tar and gzip the index dirextory.
cd $INDEX_DIR
nice -n $NICE tar czf $BACKUPDIR_TARGET/$INDEX.tgz $INDEX
cd - > /dev/null

# Create a restore script for elasticsearch
cat << EOF >> $BACKUPDIR_TARGET/${INDEX}-restore.sh
#!/bin/bash
# 
# ${INDEX}-restore.sh - restores elasticsearch index: $INDEX to elasticsearch
#   instance at $ELASTICSEARCH. This script expects to run in the same
#   directory as the $INDEX.tgz file.

# Make sure this index does not exist already
TEST=\`curl -XGET "$ELASTICSEARCH/$INDEX/_status" 2> /dev/null | grep error\`
if [ -z "\$TEST" ]; then
  echo "Index: $INDEX already exists on this elasticsearch node."
  exit 1
fi

# Extract index files
DOWNLOAD_DIR=\`pwd\`
cd $INDEX_DIR
if [ -f \$DOWNLOAD_DIR/$INDEX.tgz ]; then
  # If we have the archive, create the new index in ES
  curl -XPUT '$ELASTICSEARCH/$INDEX/' -d '$SETTINGS' > /dev/null 2>&1
  # Extract the archive in to the INDEX_DIR
  tar xzf \$DOWNLOAD_DIR/$INDEX.tgz
  # Restart elasticsearch to allow it to open the new dir and file data
  $RESTART
  exit 0
else
  echo "Unable to locate archive file \$DOWNLOAD_DIR/$INDEX.tgz."
  exit 1
fi

EOF

# Unmount the backup directory
if ! umount <%= @logstashbackupmount %>
then echo "Could not unmount backup directory"
exit 1
fi

exit 0
